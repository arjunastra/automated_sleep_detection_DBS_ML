{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "import itertools\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import TimeSeriesSplit #for time series split of data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import math, statistics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "from parsing import parse, patients\n",
    "\n",
    "from Patient_LFP import *\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "PATH = \"/Users/arjunbalachandar/Desktop/University of Toronto/Research/Fasano lab - next projects/Sleep DBS/AllFiles\"\n",
    "os.chdir(PATH)\n",
    "\n",
    "#If doing multiple files\n",
    "#with open('file_names.txt') as fn:\n",
    "#    file_names = fn.readlines()\n",
    "\n",
    "#patient_LFPs = []\n",
    "\n",
    "#fix random seed for reproducibility of random number generator\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''-----Functions-----'''\n",
    "def average_prior_LFPs(lfps, num_prior_ave, use_bisensing,use_alpha,use_beta):\n",
    "    lfp_ave = []\n",
    "    if use_bisensing:\n",
    "        if not use_alpha or not use_beta: #if sensing both sides but only want to use alpha or beta alone, then treat as if unisensing for averaging:\n",
    "            for i in range(len(lfps)):\n",
    "                row = lfps[i]\n",
    "                new_row = []\n",
    "                new_row.append(row[0])\n",
    "                if num_prior_ave == 3.0:\n",
    "                    for j in range(1,len(row)-1,1):\n",
    "                        next_ave = (row[j]+row[j-1]+row[j+1])/num_prior_ave\n",
    "                        new_row.append(next_ave)\n",
    "                elif num_prior_ave == 5.0:\n",
    "                    for j in range(2,len(row)-2,1):\n",
    "                        next_ave = (row[j]+row[j-1]+row[j-2]+row[j+1]+row[j+2])/num_prior_ave\n",
    "                        new_row.append(next_ave)\n",
    "                lfp_ave.append(new_row)\n",
    "        else:\n",
    "            for i in range(len(lfps)):\n",
    "                row = lfps[i]\n",
    "                new_row = []\n",
    "                new_row.append(row[0]) #the first 2 values of row remain same, are the value of beta/alpha at current time point\n",
    "                new_row.append(row[1])\n",
    "                if num_prior_ave == 3.0:\n",
    "                    for j in range(2,len(row)-2,2):\n",
    "                        next_ave_1 = (row[j]+row[j-2]+row[j+2])/num_prior_ave\n",
    "                        next_ave_2 = (row[j+1]+row[j-1]+row[j+3])/num_prior_ave\n",
    "                        new_row.append(next_ave_1)\n",
    "                        new_row.append(next_ave_2)\n",
    "                #0 1 2 3 4 5 6 7 8 9\n",
    "                elif num_prior_ave == 5.0:\n",
    "                    for j in range(4,len(row)-4,2):\n",
    "                        next_ave_1 = (row[j]+row[j-2]+row[j-4]+row[j+2]+row[j+4])/num_prior_ave\n",
    "                        next_ave_2 = (row[j+1]+row[j-1]+row[j-3]+row[j+3]+row[j+5])/num_prior_ave\n",
    "                        new_row.append(next_ave_1)\n",
    "                        new_row.append(next_ave_2)\n",
    "                lfp_ave.append(new_row)\n",
    "    else:\n",
    "        for i in range(len(lfps)):\n",
    "            row = lfps[i]\n",
    "            new_row = []\n",
    "            new_row.append(row[0])\n",
    "            if num_prior_ave == 3.0:\n",
    "                for j in range(1,len(row)-1,1):\n",
    "                    next_ave = (row[j]+row[j-1]+row[j+1])/num_prior_ave\n",
    "                    new_row.append(next_ave)\n",
    "            elif num_prior_ave == 5.0:\n",
    "                for j in range(2,len(row)-2,1):\n",
    "                    next_ave = (row[j]+row[j-1]+row[j-2]+row[j+1]+row[j+2])/num_prior_ave\n",
    "                    new_row.append(next_ave)\n",
    "            lfp_ave.append(new_row)\n",
    "    return lfp_ave\n",
    "\n",
    "def classify_sleep(left_patient_LFP,right_patient_LFP,use_bisensing,num_train,num_split,reverse_traintest,average_priors,num_prior_ave,use_left,use_right,use_alpha,use_beta):\n",
    "    #use_bisensing - if True, use both hemispheres if both sides recordings are present\n",
    "    if use_bisensing:\n",
    "        if left_patient_LFP.LFP_is_present and right_patient_LFP.LFP_is_present:\n",
    "            #bisensing = True\n",
    "            bisensing = True\n",
    "    else:\n",
    "        bisensing = False\n",
    "    return classify_sleep_bisensing(left_patient_LFP,right_patient_LFP,bisensing,use_bisensing,num_train,num_split,reverse_traintest,average_priors,num_prior_ave,use_left,use_right,use_alpha,use_beta) #use_bisensing is True if both electrodes are sensing, bisensing is True is want to use both\n",
    "\n",
    "def classify_sleep_bisensing(left_patient_LFP,right_patient_LFP,bisensing,use_bisensing,num_train,num_split,reverse_traintest,average_priors,num_prior_ave,use_left,use_right,use_alpha,use_beta):\n",
    "    multi_class = False #if classifying wake vs ambiguous vs deepsleep/REM, as opposed to wake vs sleep\n",
    "    kcrossv = False #if using k-fold cross validation\n",
    "    \n",
    "    #Check what specific freq band each side (or one side if unilateral sensing) is sensing\n",
    "    use_alpha_r = False\n",
    "    use_alpha_l = False\n",
    "    use_beta_r = False\n",
    "    use_beta_l = False\n",
    "\n",
    "    if use_left:\n",
    "        print(left_patient_LFP.LFP_freq_band)\n",
    "        if left_patient_LFP.LFP_freq_band == 'alpha':\n",
    "            use_alpha_l = True\n",
    "        elif left_patient_LFP.LFP_freq_band == 'beta':\n",
    "            use_beta_l = True\n",
    "    if use_right:\n",
    "        print(right_patient_LFP.LFP_freq_band)\n",
    "        if right_patient_LFP.LFP_freq_band == 'alpha':\n",
    "            use_alpha_r = True\n",
    "        elif right_patient_LFP.LFP_freq_band == 'beta':\n",
    "            use_beta_r = True\n",
    "        \n",
    "    if use_bisensing:\n",
    "        time = np.array(left_patient_LFP.time)\n",
    "        y_raw = left_patient_LFP.in_sleep\n",
    "        y_all_labels_multi = np.array(left_patient_LFP.sleep_stage_num).astype(np.int)\n",
    "    else:\n",
    "        if use_alpha_r or use_beta_r:#use_right:\n",
    "            time = np.array(right_patient_LFP.time)\n",
    "            y_raw = right_patient_LFP.in_sleep\n",
    "        else:\n",
    "            time = np.array(left_patient_LFP.time)\n",
    "            y_raw = left_patient_LFP.in_sleep\n",
    "    y_all_labels = np.array(y_raw).astype(np.int)#convert to nparray\n",
    "            \n",
    "    x_alpha = []\n",
    "    x_beta = []\n",
    "    #print('Left Freq band: ' + left_patient_LFP.LFP_freq_band)\n",
    "    if use_bisensing:\n",
    "        if left_patient_LFP.LFP_freq_band == 'beta':\n",
    "            x_beta = (np.array(left_patient_LFP.LFP)).astype(np.float)\n",
    "            x_alpha = (np.array(right_patient_LFP.LFP)).astype(np.float)\n",
    "        else:\n",
    "            x_alpha = (np.array(left_patient_LFP.LFP)).astype(np.float)\n",
    "            x_beta = (np.array(right_patient_LFP.LFP)).astype(np.float)\n",
    "        num_values = len(x_alpha)\n",
    "    else:\n",
    "        if use_beta_r:\n",
    "            x_beta = (np.array(right_patient_LFP.LFP)).astype(np.float)\n",
    "            num_values = len(x_beta)\n",
    "        elif use_alpha_r:\n",
    "            x_alpha = (np.array(right_patient_LFP.LFP)).astype(np.float)\n",
    "            num_values = len(x_alpha)\n",
    "        elif use_beta_l:\n",
    "            x_beta = (np.array(left_patient_LFP.LFP)).astype(np.float)\n",
    "            num_values = len(x_beta)\n",
    "        elif use_alpha_l:\n",
    "            x_alpha = (np.array(left_patient_LFP.LFP)).astype(np.float)\n",
    "            num_values = len(x_alpha)\n",
    "        \n",
    "    x_priors = []\n",
    "\n",
    "    if bisensing and use_bisensing: #use both alpha and beta only if want to (bisensing), even if both hemispheres being sensed (use_bisensing)\n",
    "        '''if use_alpha:\n",
    "            print(\"using alpha\")\n",
    "        if use_beta:\n",
    "            print(\"using beta\")'''\n",
    "            \n",
    "        for i in range(num_train+1):\n",
    "            prior_alpha = x_alpha[num_train-i:num_values-i]\n",
    "            prior_beta = x_beta[num_train-i:num_values-i]\n",
    "            \n",
    "            if use_alpha:\n",
    "                x_priors.append(prior_alpha)\n",
    "            if use_beta:\n",
    "                x_priors.append(prior_beta)\n",
    "    else:\n",
    "        for i in range(num_train+1):\n",
    "            if use_beta_r or use_beta_l:\n",
    "                prior_beta = x_beta[num_train-i:num_values-i]\n",
    "                x_priors.append(prior_beta)    \n",
    "            elif use_alpha_r or use_alpha_l:\n",
    "                prior_alpha = x_alpha[num_train-i:num_values-i] #IF USING ONLY ALPHA\n",
    "                x_priors.append(prior_alpha)\n",
    "\n",
    "    x_all = np.transpose(x_priors)\n",
    "    \n",
    "    #if using averaging method of priors and not raw priors themselves\n",
    "    if average_priors:\n",
    "        x_all = average_prior_LFPs(x_all, num_prior_ave, bisensing,use_alpha,use_beta)\n",
    "\n",
    "        \n",
    "    y_all_labels = y_all_labels[num_train:num_values]\n",
    "\n",
    "    \n",
    "    #for multi-class classification problem\n",
    "    '''\n",
    "    if bisensing:\n",
    "        for i in range(len(y_all_labels_multi)):\n",
    "            if (y_all_labels_multi[i] == 3 or y_all_labels_multi[i] == 4 or y_all_labels_multi[i] == 5):\n",
    "            #if (y_all_labels_multi[i] == 3 or y_all_labels_multi[i] == 4):\n",
    "                #y_all_labels_multi[i] = 2\n",
    "                y_all_labels_multi[i] = 2\n",
    "            elif (y_all_labels_multi[i] == 2):\n",
    "                y_all_labels_multi[i] = 1\n",
    "            else:\n",
    "                y_all_labels_multi[i] = 0\n",
    "        y_all_labels_multi = y_all_labels_multi[num_train:num_values]\n",
    "    '''\n",
    "    \n",
    "    #x_all_modified = np.stack((x_alpha, x_beta, y_all_labels), axis=1) #includes y_label in training features, since we'll use the preceding num_train\n",
    "    \n",
    "    kfold = KFold(n_splits=num_split, shuffle=False)# random_state=seed)\n",
    "    cvscores = [] #keeps track of each fold's accuracy\n",
    "    \n",
    "    y_pred = []\n",
    "    y_tot_test = [] #list of all labels actually used for training/testing, since some are ignored because of preventing overlap in training and testing\n",
    "\n",
    "    #model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=0)\n",
    "    #model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr')\n",
    "    #model = LogisticRegression(random_state=0)\n",
    "    #model = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "    #model = GaussianNB()\n",
    "    #model = SVC(kernel='rbf',gamma=2, C=1)\n",
    "    #model = DecisionTreeClassifier(random_state=0)\n",
    "    #model = KNeighborsClassifier()\n",
    "    #model = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100,100,100),random_state=1, max_iter=5000)\n",
    "    #model = MLPClassifier(hidden_layer_sizes=(500,500,500,500),random_state=1)\n",
    "    \n",
    "    ''''\n",
    "    if multi_class:\n",
    "        y_all_labels = y_all_labels_multi\n",
    "    '''\n",
    "    \n",
    "    if kcrossv:\n",
    "        num_test = int(len(y_all_labels)/num_split) #length of training set\n",
    "        num_tot = len(y_all_labels)\n",
    "        for i in range(num_split):\n",
    "            if i==0: #in this case, already removed firsy num_train values from list at onset earlier\n",
    "                x_test = x_all[0:num_test]\n",
    "                y_test = y_all_labels[0:num_test]\n",
    "                x_train = x_all[num_test+num_train:len(y_all_labels)]\n",
    "                y_train = y_all_labels[num_test+num_train:len(y_all_labels)]\n",
    "            elif i==(num_split-1):\n",
    "                x_train = x_all[0:(len(y_all_labels) - num_test)]\n",
    "                y_train = y_all_labels[0:(len(y_all_labels) - num_test)]\n",
    "                x_test = x_all[(len(y_all_labels) - num_test + num_train):len(y_all_labels)]\n",
    "                y_test = y_all_labels[(len(y_all_labels) - num_test + num_train):len(y_all_labels)]\n",
    "            else:\n",
    "                x_test = x_all[(num_test*i+num_train):(num_test*(i+1))]\n",
    "                y_test = y_all_labels[(num_test*i+num_train):(num_test*(i+1))]\n",
    "                x_train = [*x_all[0:(num_test*i)],*x_all[(num_test*(i+1)+num_train):len(y_all_labels)]]\n",
    "                y_train = [*y_all_labels[0:(num_test*i)],*y_all_labels[(num_test*(i+1)+num_train):len(y_all_labels)]]\n",
    "            #train model\n",
    "            clf = model.fit(x_train,y_train)\n",
    "            pred = clf.predict(x_test)\n",
    "            #overall accuracy\n",
    "            scores = clf.score(x_test,y_test)\n",
    "            cvscores.append(scores * 100)\n",
    "            #concatonate to total list of predictions/correct\n",
    "            y_pred = [*y_pred,*pred]\n",
    "            y_tot_test = [*y_tot_test,*y_test]\n",
    "            \n",
    "        print(classification_report(y_tot_test, y_pred))\n",
    "        print('Confusion Matrix')\n",
    "        con_matrix = confusion_matrix(y_tot_test, y_pred)\n",
    "        print(con_matrix)\n",
    "        print('Total Accuracy: '+str(np.mean(cvscores)))\n",
    "        AUC = roc_auc_score(y_tot_test, y_pred)\n",
    "        print('AUC: '+str(AUC))\n",
    "    else:\n",
    "        num_test = int(len(y_all_labels)/num_split)\n",
    "        if reverse_traintest:\n",
    "            x_test = x_all[0:num_test] #x_all[0:(len(y_all_labels) - num_test)]\n",
    "            y_test = y_all_labels[0:num_test]#y_all_labels[0:(len(y_all_labels) - num_test)]\n",
    "            x_train = x_all[(num_test + num_train):len(y_all_labels)]\n",
    "            y_train = y_all_labels[(num_test + num_train):len(y_all_labels)]\n",
    "        else:\n",
    "            x_train = x_all[0:(len(y_all_labels) - num_test)]\n",
    "            y_train = y_all_labels[0:(len(y_all_labels) - num_test)]\n",
    "            x_test = x_all[(len(y_all_labels) - num_test + num_train):len(y_all_labels)]\n",
    "            y_test = y_all_labels[(len(y_all_labels) - num_test + num_train):len(y_all_labels)]\n",
    "\n",
    "        print(y_test)\n",
    "        '''\n",
    "        print(num_test)\n",
    "        print(len(x_all))\n",
    "        print(len(x_train))\n",
    "        print(len(x_test))\n",
    "        print(len(y_train))\n",
    "        print(len(y_test))\n",
    "        '''\n",
    "\n",
    "        clf = model.fit(x_train,y_train)\n",
    "\n",
    "        y_pred = clf.predict(x_test)\n",
    "        print(y_pred)\n",
    "        scores = clf.score(x_test,y_test)\n",
    "        print('Scores:')\n",
    "        print(scores)\n",
    "\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print('Confusion Matrix')\n",
    "        con_matrix = confusion_matrix(y_test, y_pred)\n",
    "        print(con_matrix)\n",
    "        #print('Accuracy: '+str(np.mean(cvscores)))\n",
    "\n",
    "        #ROC\n",
    "        AUC = roc_auc_score(y_test, y_pred)\n",
    "        print('AUC: '+str(AUC))\n",
    "        \n",
    "        return [y_test,y_pred]\n",
    "    \n",
    "    '''\n",
    "    #for train, test in kfold.split(np.zeros(y_all_labels.size), y_all_labels):\n",
    "        #model.fit(x_all[train],y_all_labels[train])\n",
    "    #for train, test in cv.split(np.zeros(y_all_labels.size), y_all_labels):\n",
    "    clf = model.fit(x_all[train],y_all_labels[train])\n",
    "        \n",
    "        pred = clf.predict(x_all[test])\n",
    "        scores = clf.score(x_all[test], y_all_labels[test])\n",
    "        #print(scores)\n",
    "        cvscores.append(scores * 100)\n",
    "        tot_cvscores.append(scores * 100)\n",
    "        y_pred.append(pred[0])\n",
    "        print(time[test][0]+\" - Actual: \"+str(y_all_labels[test][0])+\" - Pred: \"+str(pred[0]))\n",
    "    \n",
    "    #Y_test = Y_all_labels #np.argmax(y_all, axis=1)\n",
    "    print(classification_report(y_all_labels, y_pred))\n",
    "    print('Confusion Matrix')\n",
    "    con_matrix = confusion_matrix(y_all_labels, y_pred)\n",
    "    print(con_matrix)\n",
    "    print('Accuracy: '+str(np.mean(cvscores)))\n",
    "\n",
    "    #ROC\n",
    "    AUC = roc_auc_score(y_all_labels, y_pred)\n",
    "    print('AUC: '+str(AUC))\n",
    "    '''\n",
    "\n",
    "#ROC AUC - function used to generate area under the curve of ROC, using inputs of predicted vs. correct category\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "#one-hot encoding: convert data representation to one-hot encoding, which is required for inputs to train machine learning classifiers in Scikit-learn\n",
    "def to_one_hot(labels, dimension):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, int(label)-1] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openfile_and_classify(fn,num_train,num_split,reverse_traintest,average_priors,num_prior_ave,use_alpha,use_beta):\n",
    "    new_path = PATH + \"/\" + fn\n",
    "    os.chdir(new_path)\n",
    "    left_LFP_file = fn + 'left_LFP.csv'\n",
    "    right_LFP_file = fn + 'right_LFP.csv'\n",
    "    #Left-hemisphere LFP file\n",
    "    \n",
    "    use_left = True\n",
    "    use_right = True\n",
    "\n",
    "    patient_left_LFP = []\n",
    "    patient_right_LFP = []\n",
    "    use_bisensing = True #use both hemisphere by default, becomes false if one side doesnt exist\n",
    "    try:\n",
    "        with open(left_LFP_file, mode ='r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            LFP_is_present = True\n",
    "            row_num = 0 #counter of which row in file currently in, first row is labels\n",
    "            LFP = []\n",
    "            time = []\n",
    "            in_sleep = []\n",
    "            sleep_stage_num = []\n",
    "            LFP_freq = 0\n",
    "            LFP_freq_band = 'beta'\n",
    "            for i in reader:\n",
    "                if row_num > 0:\n",
    "                    time.append(i[0])\n",
    "                    LFP.append(i[1])\n",
    "                    sleep_stage_num.append(i[2])\n",
    "                    in_sleep.append(i[3])\n",
    "                    LFP_freq_band = i[5]\n",
    "                    LFP_freq = i[6]\n",
    "                row_num += 1\n",
    "            patient_left_LFP = Patient_LFP(int(fn), time, LFP, sleep_stage_num, in_sleep, LFP_freq_band, LFP_freq,LFP_is_present)\n",
    "    except FileNotFoundError:\n",
    "        use_left = False\n",
    "        use_bisensing = False\n",
    "        print('File: '+ left_LFP_file +' does not exist')\n",
    "\n",
    "    #Right-hemisphere LFP file\n",
    "    try:\n",
    "        with open(right_LFP_file, mode ='r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            LFP_is_present = True\n",
    "            row_num = 0 #counter of which row in file currently in, first row is labels\n",
    "            LFP = []\n",
    "            time = []\n",
    "            in_sleep = []\n",
    "            sleep_stage_num = []\n",
    "            LFP_freq = 0\n",
    "            LFP_freq_band = 'beta'\n",
    "            for i in reader:\n",
    "                if row_num > 0:\n",
    "                    time.append(i[0])\n",
    "                    LFP.append(i[1])\n",
    "                    sleep_stage_num.append(i[2])\n",
    "                    in_sleep.append(i[3])\n",
    "                    LFP_freq_band = i[5]\n",
    "                    LFP_freq = i[6]\n",
    "                row_num += 1\n",
    "            patient_right_LFP = Patient_LFP(int(fn), time, LFP, sleep_stage_num, in_sleep, LFP_freq_band, LFP_freq,LFP_is_present)\n",
    "    except FileNotFoundError:\n",
    "        use_right = False\n",
    "        use_bisensing = False\n",
    "        print('File: '+ right_LFP_file +'does not exist')\n",
    "    return classify_sleep(patient_left_LFP,patient_right_LFP,use_bisensing,num_train,num_split,reverse_traintest,average_priors,num_prior_ave,use_left,use_right,use_alpha,use_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "beta\n",
      "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qr/d2wxfs456fsf5lgfshrqbsmw0000gn/T/ipykernel_2686/198464938.py:91: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_all_labels_multi = np.array(left_patient_LFP.sleep_stage_num).astype(np.int)\n",
      "/var/folders/qr/d2wxfs456fsf5lgfshrqbsmw0000gn/T/ipykernel_2686/198464938.py:99: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_all_labels = np.array(y_raw).astype(np.int)#convert to nparray\n",
      "/var/folders/qr/d2wxfs456fsf5lgfshrqbsmw0000gn/T/ipykernel_2686/198464938.py:109: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_alpha = (np.array(left_patient_LFP.LFP)).astype(np.float)\n",
      "/var/folders/qr/d2wxfs456fsf5lgfshrqbsmw0000gn/T/ipykernel_2686/198464938.py:110: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_beta = (np.array(right_patient_LFP.LFP)).astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Scores:\n",
      "0.6811594202898551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75       154\n",
      "           1       0.43      0.79      0.56        53\n",
      "\n",
      "    accuracy                           0.68       207\n",
      "   macro avg       0.67      0.72      0.66       207\n",
      "weighted avg       0.78      0.68      0.70       207\n",
      "\n",
      "Confusion Matrix\n",
      "[[99 55]\n",
      " [11 42]]\n",
      "AUC: 0.7176549865229109\n"
     ]
    }
   ],
   "source": [
    "'----Main Code-----'\n",
    "fn = '006'\n",
    "combineResults = False #get total confusion matrix across multiple patients if True\n",
    "reverse_traintest = False\n",
    "average_priors = False #average n-prior LFP power data points into one value, for minimizing number of training features and reduce noise\n",
    "num_prior_ave = 5.0 #number of LFP power data points to average into one value, for minimizing number of training features and reduce noise\n",
    "num_train = 100 #number of data points preceding current test point to use for training, including their labels\n",
    "num_split = 3 #for train/test split\n",
    "\n",
    "use_alpha = False #if bilateral sensing and want to just use alpha or beta, can make either False\n",
    "use_beta = True\n",
    "\n",
    "if combineResults:\n",
    "    #fns = ['002','004','007','010'] #all bilateral\n",
    "    #fns = ['002','004','007','010','005']\n",
    "    #fns = ['002','010','005'] #STN + pt005\n",
    "    #fns = ['002','010'] #STN\n",
    "    #fns = ['004','007'] #GPI\n",
    "    #fns = ['008','009','006'] #VIM\n",
    "    fns = ['008','009']\n",
    "    \n",
    "    y_test_tot = np.array([])\n",
    "    y_pred_tot = np.array([])\n",
    "    for fn in fns:\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "        if fn == '002':\n",
    "            reverse_traintest = True\n",
    "            #num_train = 80 #both\n",
    "            num_train = 80 #80 - alpha norm, ave=3 and ave=5\n",
    "        elif fn == '004':\n",
    "            reverse_traintest = False\n",
    "            #num_train = 80\n",
    "            num_train = 85 #alpha 85, or n=70, with ave=3 70/85, ave=5 with ave=3 85\n",
    "        elif fn == '007':\n",
    "            reverse_traintest = False\n",
    "            #num_train = 75\n",
    "            num_train = 80 #alpha 80, ave=3 80, ave-5 80\n",
    "        elif fn == '010':\n",
    "            reverse_traintest = False\n",
    "            #num_train = 80\n",
    "            #num_train = 75\n",
    "            num_train = 100 #alpha 100, Ave=3 85, Ave=5 85\n",
    "        elif fn == '005':\n",
    "            reverse_traintest = True\n",
    "            num_train = 70 #alpha norm 70, ave=3 70, ave=5 80\n",
    "        elif fn == '008':\n",
    "            reverse_traintest = False\n",
    "            num_train = 80 #alpha, norm 80\n",
    "        elif fn == '009':\n",
    "            reverse_traintest = True\n",
    "            num_train = 105 #alpha, norm 105\n",
    "        elif fn == '006':\n",
    "            reverse_traintest = False\n",
    "            num_train = 100 #both 90, alpha 100\n",
    "            \n",
    "        y_test,y_pred = openfile_and_classify(fn,num_train,num_split,reverse_traintest,average_priors,num_prior_ave,use_alpha,use_beta)\n",
    "        y_test_tot = np.append(y_test_tot,np.array(y_test))\n",
    "        y_pred_tot = np.append(y_pred_tot,np.array(y_pred))\n",
    "    print('Total results - norm')\n",
    "    print(classification_report(y_test_tot, y_pred_tot))\n",
    "    print('Confusion Matrix')\n",
    "    con_matrix = confusion_matrix(y_test_tot, y_pred_tot)\n",
    "    print(con_matrix)\n",
    "    AUC = roc_auc_score(y_test_tot, y_pred_tot)\n",
    "    print('AUC: '+str(AUC))\n",
    "else:\n",
    "    openfile_and_classify(fn,num_train,num_split,reverse_traintest,average_priors,num_prior_ave,use_alpha,use_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NON-PD RESULTS:\n",
    "\n",
    "--------006----------------------------\n",
    "Tics - GPI:\n",
    "\n",
    "Both alpha & beta\n",
    "n=90\n",
    "0.8416289592760181\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.79      0.88       158\n",
    "           1       0.65      0.97      0.78        63\n",
    "\n",
    "    accuracy                           0.84       221\n",
    "   macro avg       0.82      0.88      0.83       221\n",
    "weighted avg       0.89      0.84      0.85       221\n",
    "\n",
    "Confusion Matrix\n",
    "[[125  33]\n",
    " [  2  61]]\n",
    "AUC: 0.8796966043801487\n",
    "\n",
    "Ave=3, n=90\n",
    "0.8461538461538461\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.84      0.89       158\n",
    "           1       0.68      0.87      0.76        63\n",
    "\n",
    "    accuracy                           0.85       221\n",
    "   macro avg       0.81      0.85      0.82       221\n",
    "weighted avg       0.87      0.85      0.85       221\n",
    "\n",
    "Confusion Matrix\n",
    "[[132  26]\n",
    " [  8  55]]\n",
    "AUC: 0.8542294554952783\n",
    "\n",
    "Ave=5, n=80\n",
    "0.8931623931623932\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.86      0.92       160\n",
    "           1       0.76      0.96      0.85        74\n",
    "\n",
    "    accuracy                           0.89       234\n",
    "   macro avg       0.87      0.91      0.88       234\n",
    "weighted avg       0.91      0.89      0.90       234\n",
    "\n",
    "Confusion Matrix\n",
    "[[138  22]\n",
    " [  3  71]]\n",
    "AUC: 0.9109797297297297\n",
    "\n",
    "\n",
    "006\n",
    "Alpha-only\n",
    "n=100\n",
    "Scores:\n",
    "0.8792270531400966\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      0.84      0.91       154\n",
    "           1       0.68      0.98      0.81        53\n",
    "\n",
    "    accuracy                           0.88       207\n",
    "   macro avg       0.84      0.91      0.86       207\n",
    "weighted avg       0.91      0.88      0.89       207\n",
    "\n",
    "Confusion Matrix\n",
    "[[130  24]\n",
    " [  1  52]]\n",
    "AUC: 0.9126439598137711\n",
    "\n",
    "006\n",
    "Beta-only\n",
    "\n",
    " \n",
    "\n",
    "--------008-----------------------\n",
    "ET - Alpha - VIM:\n",
    "\n",
    "n=80\n",
    "0.8201219512195121\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.98      0.89       238\n",
    "           1       0.90      0.39      0.54        90\n",
    "\n",
    "    accuracy                           0.82       328\n",
    "   macro avg       0.85      0.69      0.72       328\n",
    "weighted avg       0.83      0.82      0.79       328\n",
    "\n",
    "Confusion Matrix\n",
    "[[234   4]\n",
    " [ 55  35]]\n",
    "AUC: 0.6860410830999065\n",
    " \n",
    "Ave=3, n=80\n",
    "0.8079268292682927\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.98      0.88       238\n",
    "           1       0.89      0.34      0.50        90\n",
    "\n",
    "    accuracy                           0.81       328\n",
    "   macro avg       0.84      0.66      0.69       328\n",
    "weighted avg       0.82      0.81      0.78       328\n",
    "\n",
    "Confusion Matrix\n",
    "[[234   4]\n",
    " [ 59  31]]\n",
    "AUC: 0.6638188608776844\n",
    " \n",
    " Ave = 5, n=80\n",
    "0.8323170731707317\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.98      0.89       238\n",
    "           1       0.89      0.44      0.59        90\n",
    "\n",
    "    accuracy                           0.83       328\n",
    "   macro avg       0.86      0.71      0.74       328\n",
    "weighted avg       0.84      0.83      0.81       328\n",
    "\n",
    "Confusion Matrix\n",
    "[[233   5]\n",
    " [ 50  40]]\n",
    "AUC: 0.7117180205415499\n",
    " \n",
    " \n",
    "-------------------009---------------------------------\n",
    "ET - alpha - VIM\n",
    " \n",
    "n=105\n",
    "0.8575757575757575\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.88      0.90       253\n",
    "           1       0.66      0.79      0.72        77\n",
    "\n",
    "    accuracy                           0.86       330\n",
    "   macro avg       0.80      0.83      0.81       330\n",
    "weighted avg       0.87      0.86      0.86       330\n",
    "\n",
    "Confusion Matrix\n",
    "[[222  31]\n",
    " [ 16  61]]\n",
    "AUC: 0.8348390739695087\n",
    " \n",
    "ave=3, n=105\n",
    "0.8459214501510574\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.92      0.90       254\n",
    "           1       0.70      0.60      0.64        77\n",
    "\n",
    "    accuracy                           0.85       331\n",
    "   macro avg       0.79      0.76      0.77       331\n",
    "weighted avg       0.84      0.85      0.84       331\n",
    "\n",
    "Confusion Matrix\n",
    "[[234  20]\n",
    " [ 31  46]]\n",
    "AUC: 0.7593312199611412\n",
    " \n",
    " ave=5,n=80\n",
    "0.7941176470588235\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.96      0.88       263\n",
    "           1       0.63      0.22      0.33        77\n",
    "\n",
    "    accuracy                           0.79       340\n",
    "   macro avg       0.72      0.59      0.60       340\n",
    "weighted avg       0.77      0.79      0.75       340\n",
    "\n",
    "Confusion Matrix\n",
    "[[253  10]\n",
    " [ 60  17]]\n",
    "AUC: 0.5913782035455039\n",
    " \n",
    " \n",
    " \n",
    " TOTAL ET/VIM alpha (008 + 009):\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.85      0.93      0.89       492\n",
    "         1.0       0.71      0.53      0.61       167\n",
    "\n",
    "    accuracy                           0.83       659\n",
    "   macro avg       0.78      0.73      0.75       659\n",
    "weighted avg       0.82      0.83      0.82       659\n",
    "\n",
    "Confusion Matrix\n",
    "[[456  36]\n",
    " [ 78  89]]\n",
    "AUC: 0.7298817000146051\n",
    " \n",
    " \n",
    " TOTAL VIM (ET + Tic):\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.88      0.91      0.89       646\n",
    "         1.0       0.70      0.64      0.67       220\n",
    "\n",
    "    accuracy                           0.84       866\n",
    "   macro avg       0.79      0.77      0.78       866\n",
    "weighted avg       0.84      0.84      0.84       866\n",
    "\n",
    "Confusion Matrix\n",
    "[[586  60]\n",
    " [ 79 141]]\n",
    "AUC: 0.7740149169715733\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PD (unilateral sensing):\n",
    "\n",
    "-------------005---------------------------------------\n",
    "ALPHA STN\n",
    "\n",
    "n=70\n",
    "Scores:\n",
    "0.9209726443768997\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.99      0.95       277\n",
    "           1       0.88      0.58      0.70        52\n",
    "\n",
    "    accuracy                           0.92       329\n",
    "   macro avg       0.90      0.78      0.83       329\n",
    "weighted avg       0.92      0.92      0.91       329\n",
    "\n",
    "Confusion Matrix\n",
    "[[273   4]\n",
    " [ 22  30]]\n",
    "\n",
    "Ave = 3, n=70\n",
    "0.9118541033434651\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.92      0.95       277\n",
    "           1       0.68      0.85      0.75        52\n",
    "\n",
    "    accuracy                           0.91       329\n",
    "   macro avg       0.82      0.89      0.85       329\n",
    "weighted avg       0.92      0.91      0.92       329\n",
    "\n",
    "Confusion Matrix\n",
    "[[256  21]\n",
    " [  8  44]]\n",
    "AUC: 0.8851707858928076\n",
    "\n",
    "Ave=5, n=80\n",
    "Scores:\n",
    "0.8861538461538462\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      0.88      0.93       273\n",
    "           1       0.59      0.94      0.73        52\n",
    "\n",
    "    accuracy                           0.89       325\n",
    "   macro avg       0.79      0.91      0.83       325\n",
    "weighted avg       0.92      0.89      0.90       325\n",
    "\n",
    "Confusion Matrix\n",
    "[[239  34]\n",
    " [  3  49]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TOTAL RESULTS\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "NORM RESULTS TARGET (BETA + ALPHA):\n",
    "GPI (NORM BETA + ALPHA):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.91      0.91      0.91       288\n",
    "         1.0       0.68      0.69      0.68        80\n",
    "\n",
    "    accuracy                           0.86       368\n",
    "   macro avg       0.80      0.80      0.80       368\n",
    "weighted avg       0.86      0.86      0.86       368\n",
    "\n",
    "Confusion Matrix\n",
    "[[262  26]\n",
    " [ 25  55]]\n",
    "AUC: 0.7986111111111112\n",
    "\n",
    "GPI (NORM ALPHA)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.93      0.91      0.92       262\n",
    "         1.0       0.63      0.68      0.66        59\n",
    "\n",
    "    accuracy                           0.87       321\n",
    "   macro avg       0.78      0.80      0.79       321\n",
    "weighted avg       0.87      0.87      0.87       321\n",
    "\n",
    "Confusion Matrix\n",
    "[[239  23]\n",
    " [ 19  40]]\n",
    " \n",
    "GPI (NORM BETA):\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.91      0.94      0.93       262\n",
    "         1.0       0.69      0.61      0.65        59\n",
    "\n",
    "    accuracy                           0.88       321\n",
    "   macro avg       0.80      0.77      0.79       321\n",
    "weighted avg       0.87      0.88      0.88       321\n",
    "\n",
    "Confusion Matrix\n",
    "[[246  16]\n",
    " [ 23  36]]\n",
    " \n",
    "STN (NORM BETA + ALPHA):\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.89      0.89      0.89       400\n",
    "         1.0       0.59      0.61      0.60       109\n",
    "\n",
    "    accuracy                           0.83       509\n",
    "   macro avg       0.74      0.75      0.74       509\n",
    "weighted avg       0.83      0.83      0.83       509\n",
    "\n",
    "Confusion Matrix\n",
    "[[354  46]\n",
    " [ 43  66]]\n",
    "AUC: 0.7452522935779816\n",
    "\n",
    "STN (NORM ALPHA)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.90      0.88      0.89       380\n",
    "         1.0       0.58      0.62      0.60       103\n",
    "\n",
    "    accuracy                           0.82       483\n",
    "   macro avg       0.74      0.75      0.74       483\n",
    "weighted avg       0.83      0.82      0.82       483\n",
    "\n",
    "Confusion Matrix\n",
    "[[333  47]\n",
    " [ 39  64]]\n",
    "AUC: 0.7488375063873275\n",
    "\n",
    "STN (NORM ALPHA + Pt005)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.91      0.92      0.92       657\n",
    "         1.0       0.65      0.61      0.63       155\n",
    "\n",
    "    accuracy                           0.86       812\n",
    "   macro avg       0.78      0.76      0.77       812\n",
    "weighted avg       0.86      0.86      0.86       812\n",
    "\n",
    "Confusion Matrix\n",
    "[[606  51]\n",
    " [ 61  94]]\n",
    "AUC: 0.7644130210634851\n",
    "\n",
    "STN (NORM BETA)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.92      0.87      0.89       401\n",
    "         1.0       0.61      0.75      0.67       115\n",
    "\n",
    "    accuracy                           0.84       516\n",
    "   macro avg       0.77      0.81      0.78       516\n",
    "weighted avg       0.85      0.84      0.84       516\n",
    "\n",
    "Confusion Matrix\n",
    "[[347  54]\n",
    " [ 29  86]]\n",
    "AUC: 0.8065813726553183\n",
    "\n",
    "\n",
    "\n",
    "NORM RESULTS (BETA + ALPHA)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.90      0.90      0.90       688\n",
    "         1.0       0.63      0.64      0.63       189\n",
    "\n",
    "    accuracy                           0.84       877\n",
    "   macro avg       0.76      0.77      0.77       877\n",
    "weighted avg       0.84      0.84      0.84       877\n",
    "\n",
    "Confusion Matrix\n",
    "[[616  72]\n",
    " [ 68 121]]\n",
    "AUC: 0.7677802387104713\n",
    "\n",
    "Total results - AVE=3\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.89      0.90      0.89       688\n",
    "         1.0       0.62      0.59      0.60       189\n",
    "\n",
    "    accuracy                           0.83       877\n",
    "   macro avg       0.75      0.74      0.75       877\n",
    "weighted avg       0.83      0.83      0.83       877\n",
    "\n",
    "Confusion Matrix\n",
    "[[619  69]\n",
    " [ 78 111]]\n",
    "AUC: 0.7435054448135844\n",
    "\n",
    "Total results - AVE=5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.88      0.92      0.90       683\n",
    "         1.0       0.65      0.55      0.59       189\n",
    "\n",
    "    accuracy                           0.84       872\n",
    "   macro avg       0.76      0.73      0.75       872\n",
    "weighted avg       0.83      0.84      0.83       872\n",
    "\n",
    "Confusion Matrix\n",
    "[[626  57]\n",
    " [ 85 104]]\n",
    "AUC: 0.733404603097136\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------------\n",
    "JUST BETA\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.92      0.89      0.91       663\n",
    "         1.0       0.64      0.70      0.67       174\n",
    "\n",
    "    accuracy                           0.85       837\n",
    "   macro avg       0.78      0.80      0.79       837\n",
    "weighted avg       0.86      0.85      0.86       837\n",
    "\n",
    "Confusion Matrix\n",
    "[[593  70]\n",
    " [ 52 122]]\n",
    "AUC: 0.7977843657356843\n",
    " \n",
    "AVE = 0.3\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.93      0.86      0.89       662\n",
    "         1.0       0.57      0.73      0.64       168\n",
    "\n",
    "    accuracy                           0.84       830\n",
    "   macro avg       0.75      0.80      0.77       830\n",
    "weighted avg       0.86      0.84      0.84       830\n",
    "\n",
    "Confusion Matrix\n",
    "[[571  91]\n",
    " [ 45 123]]\n",
    "AUC: 0.7973403107466551\n",
    "\n",
    "AVE = 0.5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.89      0.90      0.90       664\n",
    "         1.0       0.60      0.58      0.59       168\n",
    "\n",
    "    accuracy                           0.84       832\n",
    "   macro avg       0.75      0.74      0.74       832\n",
    "weighted avg       0.84      0.84      0.84       832\n",
    "\n",
    "Confusion Matrix\n",
    "[[600  64]\n",
    " [ 71  97]]\n",
    "AUC: 0.7404977051061388\n",
    " \n",
    "----------------------------------------------------------------------------------------------------------------------------------\n",
    "JUST ALPHA\n",
    "Norm\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.92      0.90      0.91       662\n",
    "         1.0       0.63      0.69      0.66       168\n",
    "\n",
    "    accuracy                           0.85       830\n",
    "   macro avg       0.77      0.79      0.78       830\n",
    "weighted avg       0.86      0.85      0.86       830\n",
    "\n",
    "Confusion Matrix\n",
    "[[593  69]\n",
    " [ 52 116]]\n",
    " \n",
    "JUST ALPHA WITH pt005:\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.91      0.92      0.91       924\n",
    "         1.0       0.66      0.65      0.65       229\n",
    "\n",
    "    accuracy                           0.86      1153\n",
    "   macro avg       0.78      0.78      0.78      1153\n",
    "weighted avg       0.86      0.86      0.86      1153\n",
    "\n",
    "Confusion Matrix\n",
    "[[846  78]\n",
    " [ 80 149]]\n",
    "AUC: 0.7831197187092384\n",
    "\n",
    " \n",
    "JUST ALPHA Ave=3\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.93      0.88      0.90       662\n",
    "         1.0       0.60      0.72      0.65       162\n",
    "\n",
    "    accuracy                           0.85       824\n",
    "   macro avg       0.76      0.80      0.78       824\n",
    "weighted avg       0.86      0.85      0.85       824\n",
    "\n",
    "Confusion Matrix\n",
    "[[583  79]\n",
    " [ 45 117]]\n",
    " \n",
    "JUST ALPHA Ave=3 WITH pt005:\n",
    " Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.91      0.91      0.91       944\n",
    "         1.0       0.63      0.65      0.64       229\n",
    "\n",
    "    accuracy                           0.86      1173\n",
    "   macro avg       0.77      0.78      0.78      1173\n",
    "weighted avg       0.86      0.86      0.86      1173\n",
    "\n",
    "Confusion Matrix\n",
    "[[856  88]\n",
    " [ 80 149]]\n",
    "AUC: 0.7787173414255052\n",
    " \n",
    "\n",
    "JUST ALPHA Ave=5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.91      0.91      0.91       662\n",
    "         1.0       0.64      0.62      0.63       162\n",
    "\n",
    "    accuracy                           0.86       824\n",
    "   macro avg       0.77      0.77      0.77       824\n",
    "weighted avg       0.86      0.86      0.86       824\n",
    "\n",
    "Confusion Matrix\n",
    "[[605  57]\n",
    " [ 61 101]]\n",
    "AUC: 0.7686770355451121\n",
    "\n",
    "JUST ALPHA Ave=5 WITH pt005:\n",
    "Total results - norm\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.91      0.88      0.90       940\n",
    "         1.0       0.57      0.65      0.61       229\n",
    "\n",
    "    accuracy                           0.83      1169\n",
    "   macro avg       0.74      0.77      0.75      1169\n",
    "weighted avg       0.84      0.83      0.84      1169\n",
    "\n",
    "Confusion Matrix\n",
    "[[827 113]\n",
    " [ 80 149]]\n",
    "AUC: 0.7652211279383072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n-----------------------------------------------------------------------------------------------------------------------------------------------\\nNORM RESULTS TARGET (BETA + ALPHA):\\nGPI (NORM BETA + ALPHA):\\n              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.91      0.91       288\\n         1.0       0.68      0.69      0.68        80\\n\\n    accuracy                           0.86       368\\n   macro avg       0.80      0.80      0.80       368\\nweighted avg       0.86      0.86      0.86       368\\n\\nConfusion Matrix\\n[[262  26]\\n [ 25  55]]\\nAUC: 0.7986111111111112\\n\\nGPI (NORM ALPHA)\\n              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.91      0.92       262\\n         1.0       0.63      0.68      0.66        59\\n\\n    accuracy                           0.87       321\\n   macro avg       0.78      0.80      0.79       321\\nweighted avg       0.87      0.87      0.87       321\\n\\nConfusion Matrix\\n[[239  23]\\n [ 19  40]]\\n \\nGPI (NORM BETA):\\nTotal results - norm\\n              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.94      0.93       262\\n         1.0       0.69      0.61      0.65        59\\n\\n    accuracy                           0.88       321\\n   macro avg       0.80      0.77      0.79       321\\nweighted avg       0.87      0.88      0.88       321\\n\\nConfusion Matrix\\n[[246  16]\\n [ 23  36]]\\n \\nSTN (NORM BETA + ALPHA):\\nTotal results - norm\\n              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.89      0.89       400\\n         1.0       0.59      0.61      0.60       109\\n\\n    accuracy                           0.83       509\\n   macro avg       0.74      0.75      0.74       509\\nweighted avg       0.83      0.83      0.83       509\\n\\nConfusion Matrix\\n[[354  46]\\n [ 43  66]]\\nAUC: 0.7452522935779816\\n\\nSTN (NORM ALPHA)\\n              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.88      0.89       380\\n         1.0       0.58      0.62      0.60       103\\n\\n    accuracy                           0.82       483\\n   macro avg       0.74      0.75      0.74       483\\nweighted avg       0.83      0.82      0.82       483\\n\\nConfusion Matrix\\n[[333  47]\\n [ 39  64]]\\nAUC: 0.7488375063873275\\n\\nSTN (NORM BETA)\\n              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.87      0.89       401\\n         1.0       0.61      0.75      0.67       115\\n\\n    accuracy                           0.84       516\\n   macro avg       0.77      0.81      0.78       516\\nweighted avg       0.85      0.84      0.84       516\\n\\nConfusion Matrix\\n[[347  54]\\n [ 29  86]]\\nAUC: 0.8065813726553183\\n\\n\\n\\n\\nNORM RESULTS (BETA + ALPHA)\\n              precision    recall  f1-score   support\\n\\n         0.0       0.90      0.90      0.90       688\\n         1.0       0.63      0.64      0.63       189\\n\\n    accuracy                           0.84       877\\n   macro avg       0.76      0.77      0.77       877\\nweighted avg       0.84      0.84      0.84       877\\n\\nConfusion Matrix\\n[[616  72]\\n [ 68 121]]\\nAUC: 0.7677802387104713\\n\\nTotal results - AVE=3\\n              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.90      0.89       688\\n         1.0       0.62      0.59      0.60       189\\n\\n    accuracy                           0.83       877\\n   macro avg       0.75      0.74      0.75       877\\nweighted avg       0.83      0.83      0.83       877\\n\\nConfusion Matrix\\n[[619  69]\\n [ 78 111]]\\nAUC: 0.7435054448135844\\n\\nTotal results - AVE=5\\n              precision    recall  f1-score   support\\n\\n         0.0       0.88      0.92      0.90       683\\n         1.0       0.65      0.55      0.59       189\\n\\n    accuracy                           0.84       872\\n   macro avg       0.76      0.73      0.75       872\\nweighted avg       0.83      0.84      0.83       872\\n\\nConfusion Matrix\\n[[626  57]\\n [ 85 104]]\\nAUC: 0.733404603097136\\n\\n----------------------------------------------------------------------------------------------------------------------------------\\nJUST BETA\\nTotal results - norm\\n              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.89      0.91       663\\n         1.0       0.64      0.70      0.67       174\\n\\n    accuracy                           0.85       837\\n   macro avg       0.78      0.80      0.79       837\\nweighted avg       0.86      0.85      0.86       837\\n\\nConfusion Matrix\\n[[593  70]\\n [ 52 122]]\\nAUC: 0.7977843657356843\\n \\nAVE = 0.3\\n              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.86      0.89       662\\n         1.0       0.57      0.73      0.64       168\\n\\n    accuracy                           0.84       830\\n   macro avg       0.75      0.80      0.77       830\\nweighted avg       0.86      0.84      0.84       830\\n\\nConfusion Matrix\\n[[571  91]\\n [ 45 123]]\\nAUC: 0.7973403107466551\\n\\nAVE = 0.5\\n              precision    recall  f1-score   support\\n\\n         0.0       0.89      0.90      0.90       664\\n         1.0       0.60      0.58      0.59       168\\n\\n    accuracy                           0.84       832\\n   macro avg       0.75      0.74      0.74       832\\nweighted avg       0.84      0.84      0.84       832\\n\\nConfusion Matrix\\n[[600  64]\\n [ 71  97]]\\nAUC: 0.7404977051061388\\n \\n----------------------------------------------------------------------------------------------------------------------------------\\nJUST ALPHA\\nNorm\\nTotal results - norm\\n              precision    recall  f1-score   support\\n\\n         0.0       0.92      0.90      0.91       662\\n         1.0       0.63      0.69      0.66       168\\n\\n    accuracy                           0.85       830\\n   macro avg       0.77      0.79      0.78       830\\nweighted avg       0.86      0.85      0.86       830\\n\\nConfusion Matrix\\n[[593  69]\\n [ 52 116]]\\n \\nJUST ALPHA Ave=3\\nTotal results - norm\\n              precision    recall  f1-score   support\\n\\n         0.0       0.93      0.88      0.90       662\\n         1.0       0.60      0.72      0.65       162\\n\\n    accuracy                           0.85       824\\n   macro avg       0.76      0.80      0.78       824\\nweighted avg       0.86      0.85      0.85       824\\n\\nConfusion Matrix\\n[[583  79]\\n [ 45 117]]\\n \\n\\nJUST ALPHA Ave=5\\n              precision    recall  f1-score   support\\n\\n         0.0       0.91      0.91      0.91       662\\n         1.0       0.64      0.62      0.63       162\\n\\n    accuracy                           0.86       824\\n   macro avg       0.77      0.77      0.77       824\\nweighted avg       0.86      0.86      0.86       824\\n\\nConfusion Matrix\\n[[605  57]\\n [ 61 101]]\\nAUC: 0.7686770355451121\\n\\n\\n----------------------------------------------------------------------------------------------------------------------------------\\nRESULTS:\\n010\\nnum_train = 80 #number of data points preceding current test point to use for training, including their labels\\nnum_split = 3 \\nScores:\\n0.855072463768116\\n              precision    recall  f1-score   support\\n\\n           0       0.97      0.85      0.91       177\\n           1       0.50      0.87      0.63        30\\n\\n    accuracy                           0.86       207\\n   macro avg       0.74      0.86      0.77       207\\nweighted avg       0.91      0.86      0.87       207\\n\\nConfusion Matrix\\n[[151  26]\\n [  4  26]]\\nAUC: 0.8598870056497175\\n[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0]\\n \\n 010\\n JUST BETA n=70\\n [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8461538461538461\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.81      0.89       178\\n           1       0.56      1.00      0.72        43\\n\\n    accuracy                           0.85       221\\n   macro avg       0.78      0.90      0.81       221\\nweighted avg       0.91      0.85      0.86       221\\n\\nConfusion Matrix\\n[[144  34]\\n [  0  43]]\\nAUC: 0.9044943820224719\\n\\n010 - AVE = 0.5\\n[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\\nScores:\\n0.8792270531400966\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.86      0.92       177\\n           1       0.55      1.00      0.71        30\\n\\n    accuracy                           0.88       207\\n   macro avg       0.77      0.93      0.81       207\\nweighted avg       0.93      0.88      0.89       207\\n\\nConfusion Matrix\\n[[152  25]\\n [  0  30]]\\nAUC: 0.9293785310734463\\n\\n010\\nAVE = 0.3\\n[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\\nScores:\\n0.855072463768116\\n              precision    recall  f1-score   support\\n\\n           0       0.99      0.84      0.91       177\\n           1       0.50      0.97      0.66        30\\n\\n    accuracy                           0.86       207\\n   macro avg       0.75      0.90      0.78       207\\nweighted avg       0.92      0.86      0.87       207\\n\\nConfusion Matrix\\n[[148  29]\\n [  1  29]]\\nAUC: 0.9014124293785312\\n\\n010 - JUST BETA - AVE = 0.3\\n[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\\nScores:\\n0.8309178743961353\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.80      0.89       177\\n           1       0.46      1.00      0.63        30\\n\\n    accuracy                           0.83       207\\n   macro avg       0.73      0.90      0.76       207\\nweighted avg       0.92      0.83      0.85       207\\n\\nConfusion Matrix\\n[[142  35]\\n [  0  30]]\\nAUC: 0.9011299435028248\\n\\n010 - JUST BETA n=85 - AVE = 0.5\\n0.9253731343283582\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.92      0.96       177\\n           1       0.62      1.00      0.76        24\\n\\n    accuracy                           0.93       201\\n   macro avg       0.81      0.96      0.86       201\\nweighted avg       0.95      0.93      0.93       201\\n\\nConfusion Matrix\\n[[162  15]\\n [  0  24]]\\nAUC: 0.9576271186440678\\n\\n\\n---010 JUST ALPHA---\\n010 JUST ALPHA Norm n=100\\n0.9005524861878453\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.89      0.94       157\\n           1       0.57      1.00      0.73        24\\n\\n    accuracy                           0.90       181\\n   macro avg       0.79      0.94      0.83       181\\nweighted avg       0.94      0.90      0.91       181\\n\\nConfusion Matrix\\n[[139  18]\\n [  0  24]]\\n \\n010 JUST ALPHA Norm n=80\\nScores:\\n0.845771144278607\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.82      0.90       177\\n           1       0.44      1.00      0.61        24\\n\\n    accuracy                           0.85       201\\n   macro avg       0.72      0.91      0.76       201\\nweighted avg       0.93      0.85      0.87       201\\n\\nConfusion Matrix\\n[[146  31]\\n [  0  24]]\\nAUC: 0.9124293785310734\\n\\n010 Ave = 3 N=85\\nScores:\\n0.8855721393034826\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.87      0.93       177\\n           1       0.51      1.00      0.68        24\\n\\n    accuracy                           0.89       201\\n   macro avg       0.76      0.94      0.80       201\\nweighted avg       0.94      0.89      0.90       201\\n\\nConfusion Matrix\\n[[154  23]\\n [  0  24]]\\nAUC: 0.9350282485875706\\n\\n\\n010 JUST ALPHA Ave=5 n=85\\n0.9253731343283582\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.92      0.96       177\\n           1       0.62      1.00      0.76        24\\n\\n    accuracy                           0.93       201\\n   macro avg       0.81      0.96      0.86       201\\nweighted avg       0.95      0.93      0.93       201\\n\\nConfusion Matrix\\n[[162  15]\\n [  0  24]]\\nAUC: 0.9576271186440678\\n\\n\\n----------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n----004-----\\n\\nnum_train = 80 #number of data points preceding current test point to use for training, including their labels\\nnum_split = 3\\n0.8960573476702509\\n              precision    recall  f1-score   support\\n\\n           0       0.91      0.98      0.94       239\\n           1       0.76      0.40      0.52        40\\n\\n    accuracy                           0.90       279\\n   macro avg       0.83      0.69      0.73       279\\nweighted avg       0.89      0.90      0.88       279\\n\\nConfusion Matrix\\n[[234   5]\\n [ 24  16]]\\nAUC: 0.6895397489539749\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n \\nn=70\\n0.8672566371681416\\n              precision    recall  f1-score   support\\n\\n           0       0.88      0.97      0.92       186\\n           1       0.75      0.38      0.50        40\\n\\n    accuracy                           0.87       226\\n   macro avg       0.81      0.67      0.71       226\\nweighted avg       0.86      0.87      0.85       226\\n\\nConfusion Matrix\\n[[181   5]\\n [ 25  15]]\\nAUC: 0.6740591397849462\\n \\n 004\\n JUST BETA\\n n=70\\n [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8726415094339622\\n              precision    recall  f1-score   support\\n\\n           0       0.88      0.98      0.93       172\\n           1       0.84      0.40      0.54        40\\n\\n    accuracy                           0.87       212\\n   macro avg       0.86      0.69      0.73       212\\nweighted avg       0.87      0.87      0.85       212\\n\\nConfusion Matrix\\n[[169   3]\\n [ 24  16]]\\nAUC: 0.6912790697674418\\n\\n004 - AVE = 3\\n[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8632075471698113\\n              precision    recall  f1-score   support\\n\\n           0       0.87      0.97      0.92       172\\n           1       0.76      0.40      0.52        40\\n\\n    accuracy                           0.86       212\\n   macro avg       0.82      0.69      0.72       212\\nweighted avg       0.85      0.86      0.85       212\\n\\nConfusion Matrix\\n[[167   5]\\n [ 24  16]]\\nAUC: 0.6854651162790697\\n\\n004 - AVE = 5\\n[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.839622641509434\\n              precision    recall  f1-score   support\\n\\n           0       0.85      0.98      0.91       172\\n           1       0.71      0.25      0.37        40\\n\\n    accuracy                           0.84       212\\n   macro avg       0.78      0.61      0.64       212\\nweighted avg       0.82      0.84      0.81       212\\n\\nConfusion Matrix\\n[[168   4]\\n [ 30  10]]\\nAUC: 0.6133720930232558\\n \\n \\n -------------------------------------------------\\n -----007-----\\n n=70 norm\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8445945945945946\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.79      0.88       108\\n           1       0.63      1.00      0.78        40\\n\\n    accuracy                           0.84       148\\n   macro avg       0.82      0.89      0.83       148\\nweighted avg       0.90      0.84      0.85       148\\n\\nConfusion Matrix\\n[[85 23]\\n [ 0 40]]\\nAUC: 0.8935185185185185\\n\\nn=75 norm\\nScores:\\n0.852112676056338\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.79      0.89       102\\n           1       0.66      1.00      0.79        40\\n\\n    accuracy                           0.85       142\\n   macro avg       0.83      0.90      0.84       142\\nweighted avg       0.90      0.85      0.86       142\\n\\nConfusion Matrix\\n[[81 21]\\n [ 0 40]]\\nAUC: 0.8970588235294118\\n\\n\\nAVERAGING n=3:\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8716216216216216\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.82      0.90       108\\n           1       0.68      1.00      0.81        40\\n\\n    accuracy                           0.87       148\\n   macro avg       0.84      0.91      0.86       148\\nweighted avg       0.91      0.87      0.88       148\\n\\nConfusion Matrix\\n[[89 19]\\n [ 0 40]]\\nAUC: 0.912037037037037\\n\\nAVE=3 n=75\\nScores:\\n0.8873239436619719\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.84      0.91       102\\n           1       0.71      1.00      0.83        40\\n\\n    accuracy                           0.89       142\\n   macro avg       0.86      0.92      0.87       142\\nweighted avg       0.92      0.89      0.89       142\\n\\nConfusion Matrix\\n[[86 16]\\n [ 0 40]]\\nAUC: 0.9215686274509804\\n\\n007 - AVE=5\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8740740740740741\\n              precision    recall  f1-score   support\\n\\n           0       1.00      0.82      0.90        95\\n           1       0.70      1.00      0.82        40\\n\\n    accuracy                           0.87       135\\n   macro avg       0.85      0.91      0.86       135\\nweighted avg       0.91      0.87      0.88       135\\n\\nConfusion Matrix\\n[[78 17]\\n [ 0 40]]\\n\\n007 JUST BETA:\\nn=80\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8518518518518519\\n              precision    recall  f1-score   support\\n\\n           0       0.95      0.83      0.89        95\\n           1       0.69      0.90      0.78        40\\n\\n    accuracy                           0.85       135\\n   macro avg       0.82      0.87      0.84       135\\nweighted avg       0.87      0.85      0.86       135\\n\\nConfusion Matrix\\n[[79 16]\\n [ 4 36]]\\nAUC: 0.8657894736842106\\n\\n007 JUST BETA:\\nAVERAGING n=3:\\nn=80:\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\\nScores:\\n0.8962962962962963\\n              precision    recall  f1-score   support\\n\\n           0       0.99      0.86      0.92        95\\n           1       0.75      0.97      0.85        40\\n\\n    accuracy                           0.90       135\\n   macro avg       0.87      0.92      0.88       135\\nweighted avg       0.92      0.90      0.90       135\\n\\nConfusion Matrix\\n[[82 13]\\n [ 1 39]]\\nAUC: 0.9190789473684211\\n\\n007 JUST BETA AVE=3 n=75\\nScores:\\n0.8943661971830986\\n              precision    recall  f1-score   support\\n\\n           0       0.98      0.87      0.92       102\\n           1       0.75      0.95      0.84        40\\n\\n    accuracy                           0.89       142\\n   macro avg       0.86      0.91      0.88       142\\nweighted avg       0.91      0.89      0.90       142\\n\\nConfusion Matrix\\n[[89 13]\\n [ 2 38]]\\nAUC: 0.9112745098039216\\n\\n\\n007 JUST BETA Ave=5 n=75\\nScores:\\n0.8591549295774648\\n              precision    recall  f1-score   support\\n\\n           0       0.96      0.84      0.90       102\\n           1       0.69      0.90      0.78        40\\n\\n    accuracy                           0.86       142\\n   macro avg       0.82      0.87      0.84       142\\nweighted avg       0.88      0.86      0.86       142\\n\\nConfusion Matrix\\n[[86 16]\\n [ 4 36]]\\nAUC: 0.8715686274509803\\n\\n007 JUST BETA Ave=5 n=80\\nScores:\\n0.8814814814814815\\n              precision    recall  f1-score   support\\n\\n           0       0.95      0.87      0.91        95\\n           1       0.75      0.90      0.82        40\\n\\n    accuracy                           0.88       135\\n   macro avg       0.85      0.89      0.87       135\\nweighted avg       0.89      0.88      0.88       135\\n\\nConfusion Matrix\\n[[83 12]\\n [ 4 36]]\\nAUC: 0.8868421052631579\\n\\n\\n007 JUST ALPHA\\nNorm n=80\\nScores:\\n0.8518518518518519\\n              precision    recall  f1-score   support\\n\\n           0       0.95      0.83      0.89        95\\n           1       0.69      0.90      0.78        40\\n\\n    accuracy                           0.85       135\\n   macro avg       0.82      0.87      0.84       135\\nweighted avg       0.87      0.85      0.86       135\\n\\nConfusion Matrix\\n[[79 16]\\n [ 4 36]]\\nAUC: 0.8657894736842106\\n\\n007 JUST ALPHA Ave=3 n=80\\n0.8962962962962963\\n              precision    recall  f1-score   support\\n\\n           0       0.99      0.86      0.92        95\\n           1       0.75      0.97      0.85        40\\n\\n    accuracy                           0.90       135\\n   macro avg       0.87      0.92      0.88       135\\nweighted avg       0.92      0.90      0.90       135\\n\\nConfusion Matrix\\n[[82 13]\\n [ 1 39]]\\nAUC: 0.9190789473684211\\n\\n007 JUST ALPHA Ave=3 n=80\\n0.8814814814814815\\n              precision    recall  f1-score   support\\n\\n           0       0.95      0.87      0.91        95\\n           1       0.75      0.90      0.82        40\\n\\n    accuracy                           0.88       135\\n   macro avg       0.85      0.89      0.87       135\\nweighted avg       0.89      0.88      0.88       135\\n\\nConfusion Matrix\\n[[83 12]\\n [ 4 36]]\\nAUC: 0.8868421052631579\\n\\n---------------------------------------------------------------------------------------------------------------------------------------------------\\n-------002-------\\nJUST BETA\\nn=80\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\n[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1\\n 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\nScores:\\n0.8344370860927153\\n              precision    recall  f1-score   support\\n\\n           0       0.87      0.91      0.89       223\\n           1       0.70      0.63      0.67        79\\n\\n    accuracy                           0.83       302\\n   macro avg       0.79      0.77      0.78       302\\nweighted avg       0.83      0.83      0.83       302\\n\\nConfusion Matrix\\n[[202  21]\\n [ 29  50]]\\nAUC: 0.7693704944088097\\n\\n002\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\n[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\nScores:\\n0.804635761589404\\n              precision    recall  f1-score   support\\n\\n           0       0.84      0.91      0.87       223\\n           1       0.67      0.51      0.58        79\\n\\n    accuracy                           0.80       302\\n   macro avg       0.75      0.71      0.72       302\\nweighted avg       0.79      0.80      0.80       302\\n\\nConfusion Matrix\\n[[203  20]\\n [ 39  40]]\\nAUC: 0.708321507634671\\n\\n002\\nAveraging = 3\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\n[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\nScores:\\n0.7649006622516556\\n              precision    recall  f1-score   support\\n\\n           0       0.80      0.91      0.85       223\\n           1       0.58      0.35      0.44        79\\n\\n    accuracy                           0.76       302\\n   macro avg       0.69      0.63      0.65       302\\nweighted avg       0.74      0.76      0.74       302\\n\\nConfusion Matrix\\n[[203  20]\\n [ 51  28]]\\nAUC: 0.6323721405460635\\n\\n002 - JUST BETA - AVE =3\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\n[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1\\n 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\nScores:\\n0.8344370860927153\\n              precision    recall  f1-score   support\\n\\n           0       0.87      0.91      0.89       223\\n           1       0.70      0.63      0.67        79\\n\\n    accuracy                           0.83       302\\n   macro avg       0.79      0.77      0.78       302\\nweighted avg       0.83      0.83      0.83       302\\n\\nConfusion Matrix\\n[[202  21]\\n [ 29  50]]\\nAUC: 0.7693704944088097\\n\\nScores:\\n0.7748344370860927\\n              precision    recall  f1-score   support\\n\\n           0       0.88      0.81      0.84       223\\n           1       0.56      0.68      0.61        79\\n\\n    accuracy                           0.77       302\\n   macro avg       0.72      0.75      0.73       302\\nweighted avg       0.79      0.77      0.78       302\\n\\nConfusion Matrix\\n[[180  43]\\n [ 25  54]]\\nAUC: 0.7453595958449226\\n\\n\\n002 - AVE = 5\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\n[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\nScores:\\n0.804635761589404\\n              precision    recall  f1-score   support\\n\\n           0       0.84      0.91      0.87       223\\n           1       0.67      0.51      0.58        79\\n\\n    accuracy                           0.80       302\\n   macro avg       0.75      0.71      0.72       302\\nweighted avg       0.79      0.80      0.80       302\\n\\nConfusion Matrix\\n[[203  20]\\n [ 39  40]]\\nAUC: 0.708321507634671\\n\\n002 - JUST BETA - n=5\\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\\n 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\\n 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\n[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1\\n 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1\\n 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n 0 0 0 0 0 0]\\nScores:\\n0.8344370860927153\\n              precision    recall  f1-score   support\\n\\n           0       0.87      0.91      0.89       223\\n           1       0.70      0.63      0.67        79\\n\\n    accuracy                           0.83       302\\n   macro avg       0.79      0.77      0.78       302\\nweighted avg       0.83      0.83      0.83       302\\n\\nConfusion Matrix\\n[[202  21]\\n [ 29  50]]\\nAUC: 0.7693704944088097\\n\\n\\n\\n002 JUST ALPHA\\nNorm n=80\\n0.8344370860927153\\n              precision    recall  f1-score   support\\n\\n           0       0.87      0.91      0.89       223\\n           1       0.70      0.63      0.67        79\\n\\n    accuracy                           0.83       302\\n   macro avg       0.79      0.77      0.78       302\\nweighted avg       0.83      0.83      0.83       302\\n\\nConfusion Matrix\\n[[202  21]\\n [ 29  50]]\\nAUC: 0.7693704944088097\\n\\n002 JUST ALPHA Ave=3 N=80\\n0.7873754152823921\\n              precision    recall  f1-score   support\\n\\n           0       0.90      0.80      0.85       222\\n           1       0.57      0.76      0.65        79\\n\\n    accuracy                           0.79       301\\n   macro avg       0.74      0.78      0.75       301\\nweighted avg       0.82      0.79      0.80       301\\n\\nConfusion Matrix\\n[[177  45]\\n [ 19  60]]\\nAUC: 0.7783954840916867\\n\\n002 JUST ALPHA Ave=5 N=80\\n0.7748344370860927\\n              precision    recall  f1-score   support\\n\\n           0       0.84      0.87      0.85       223\\n           1       0.58      0.52      0.55        79\\n\\n    accuracy                           0.77       302\\n   macro avg       0.71      0.69      0.70       302\\nweighted avg       0.77      0.77      0.77       302\\n\\nConfusion Matrix\\n[[193  30]\\n [ 38  41]]\\nAUC: 0.6922290968950446\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''----------------------------------------------------------------------------------------------------------------------------------\n",
    "INDIVIDUAL RESULTS:\n",
    "\n",
    "---010-------------\n",
    "010\n",
    "num_train = 80 #number of data points preceding current test point to use for training, including their labels\n",
    "num_split = 3 \n",
    "Scores:\n",
    "0.855072463768116\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.85      0.91       177\n",
    "           1       0.50      0.87      0.63        30\n",
    "\n",
    "    accuracy                           0.86       207\n",
    "   macro avg       0.74      0.86      0.77       207\n",
    "weighted avg       0.91      0.86      0.87       207\n",
    "\n",
    "Confusion Matrix\n",
    "[[151  26]\n",
    " [  4  26]]\n",
    "AUC: 0.8598870056497175\n",
    "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0]\n",
    " \n",
    " 010\n",
    " JUST BETA n=70\n",
    " [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8461538461538461\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.81      0.89       178\n",
    "           1       0.56      1.00      0.72        43\n",
    "\n",
    "    accuracy                           0.85       221\n",
    "   macro avg       0.78      0.90      0.81       221\n",
    "weighted avg       0.91      0.85      0.86       221\n",
    "\n",
    "Confusion Matrix\n",
    "[[144  34]\n",
    " [  0  43]]\n",
    "AUC: 0.9044943820224719\n",
    "\n",
    "010 - AVE = 0.5\n",
    "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
    "Scores:\n",
    "0.8792270531400966\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.86      0.92       177\n",
    "           1       0.55      1.00      0.71        30\n",
    "\n",
    "    accuracy                           0.88       207\n",
    "   macro avg       0.77      0.93      0.81       207\n",
    "weighted avg       0.93      0.88      0.89       207\n",
    "\n",
    "Confusion Matrix\n",
    "[[152  25]\n",
    " [  0  30]]\n",
    "AUC: 0.9293785310734463\n",
    "\n",
    "010\n",
    "AVE = 0.3\n",
    "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
    "Scores:\n",
    "0.855072463768116\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      0.84      0.91       177\n",
    "           1       0.50      0.97      0.66        30\n",
    "\n",
    "    accuracy                           0.86       207\n",
    "   macro avg       0.75      0.90      0.78       207\n",
    "weighted avg       0.92      0.86      0.87       207\n",
    "\n",
    "Confusion Matrix\n",
    "[[148  29]\n",
    " [  1  29]]\n",
    "AUC: 0.9014124293785312\n",
    "\n",
    "010 - JUST BETA - AVE = 0.3\n",
    "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
    "Scores:\n",
    "0.8309178743961353\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.80      0.89       177\n",
    "           1       0.46      1.00      0.63        30\n",
    "\n",
    "    accuracy                           0.83       207\n",
    "   macro avg       0.73      0.90      0.76       207\n",
    "weighted avg       0.92      0.83      0.85       207\n",
    "\n",
    "Confusion Matrix\n",
    "[[142  35]\n",
    " [  0  30]]\n",
    "AUC: 0.9011299435028248\n",
    "\n",
    "010 - JUST BETA n=85 - AVE = 0.5\n",
    "0.9253731343283582\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.92      0.96       177\n",
    "           1       0.62      1.00      0.76        24\n",
    "\n",
    "    accuracy                           0.93       201\n",
    "   macro avg       0.81      0.96      0.86       201\n",
    "weighted avg       0.95      0.93      0.93       201\n",
    "\n",
    "Confusion Matrix\n",
    "[[162  15]\n",
    " [  0  24]]\n",
    "AUC: 0.9576271186440678\n",
    "\n",
    "\n",
    "---010 JUST ALPHA---\n",
    "010 JUST ALPHA Norm n=100\n",
    "0.9005524861878453\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.89      0.94       157\n",
    "           1       0.57      1.00      0.73        24\n",
    "\n",
    "    accuracy                           0.90       181\n",
    "   macro avg       0.79      0.94      0.83       181\n",
    "weighted avg       0.94      0.90      0.91       181\n",
    "\n",
    "Confusion Matrix\n",
    "[[139  18]\n",
    " [  0  24]]\n",
    " \n",
    "010 JUST ALPHA Norm n=80\n",
    "Scores:\n",
    "0.845771144278607\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.82      0.90       177\n",
    "           1       0.44      1.00      0.61        24\n",
    "\n",
    "    accuracy                           0.85       201\n",
    "   macro avg       0.72      0.91      0.76       201\n",
    "weighted avg       0.93      0.85      0.87       201\n",
    "\n",
    "Confusion Matrix\n",
    "[[146  31]\n",
    " [  0  24]]\n",
    "AUC: 0.9124293785310734\n",
    "\n",
    "010 Ave = 3 N=85\n",
    "Scores:\n",
    "0.8855721393034826\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.87      0.93       177\n",
    "           1       0.51      1.00      0.68        24\n",
    "\n",
    "    accuracy                           0.89       201\n",
    "   macro avg       0.76      0.94      0.80       201\n",
    "weighted avg       0.94      0.89      0.90       201\n",
    "\n",
    "Confusion Matrix\n",
    "[[154  23]\n",
    " [  0  24]]\n",
    "AUC: 0.9350282485875706\n",
    "\n",
    "\n",
    "010 JUST ALPHA Ave=5 n=85\n",
    "0.9253731343283582\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.92      0.96       177\n",
    "           1       0.62      1.00      0.76        24\n",
    "\n",
    "    accuracy                           0.93       201\n",
    "   macro avg       0.81      0.96      0.86       201\n",
    "weighted avg       0.95      0.93      0.93       201\n",
    "\n",
    "Confusion Matrix\n",
    "[[162  15]\n",
    " [  0  24]]\n",
    "AUC: 0.9576271186440678\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "----004-----\n",
    "\n",
    "num_train = 80 #number of data points preceding current test point to use for training, including their labels\n",
    "num_split = 3\n",
    "0.8960573476702509\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.98      0.94       239\n",
    "           1       0.76      0.40      0.52        40\n",
    "\n",
    "    accuracy                           0.90       279\n",
    "   macro avg       0.83      0.69      0.73       279\n",
    "weighted avg       0.89      0.90      0.88       279\n",
    "\n",
    "Confusion Matrix\n",
    "[[234   5]\n",
    " [ 24  16]]\n",
    "AUC: 0.6895397489539749\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    " \n",
    "n=70\n",
    "0.8672566371681416\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.97      0.92       186\n",
    "           1       0.75      0.38      0.50        40\n",
    "\n",
    "    accuracy                           0.87       226\n",
    "   macro avg       0.81      0.67      0.71       226\n",
    "weighted avg       0.86      0.87      0.85       226\n",
    "\n",
    "Confusion Matrix\n",
    "[[181   5]\n",
    " [ 25  15]]\n",
    "AUC: 0.6740591397849462\n",
    " \n",
    " 004\n",
    " JUST BETA\n",
    " n=70\n",
    " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8726415094339622\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.98      0.93       172\n",
    "           1       0.84      0.40      0.54        40\n",
    "\n",
    "    accuracy                           0.87       212\n",
    "   macro avg       0.86      0.69      0.73       212\n",
    "weighted avg       0.87      0.87      0.85       212\n",
    "\n",
    "Confusion Matrix\n",
    "[[169   3]\n",
    " [ 24  16]]\n",
    "AUC: 0.6912790697674418\n",
    "\n",
    "004 - AVE = 3\n",
    "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8632075471698113\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.97      0.92       172\n",
    "           1       0.76      0.40      0.52        40\n",
    "\n",
    "    accuracy                           0.86       212\n",
    "   macro avg       0.82      0.69      0.72       212\n",
    "weighted avg       0.85      0.86      0.85       212\n",
    "\n",
    "Confusion Matrix\n",
    "[[167   5]\n",
    " [ 24  16]]\n",
    "AUC: 0.6854651162790697\n",
    "\n",
    "004 - AVE = 5\n",
    "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.839622641509434\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.98      0.91       172\n",
    "           1       0.71      0.25      0.37        40\n",
    "\n",
    "    accuracy                           0.84       212\n",
    "   macro avg       0.78      0.61      0.64       212\n",
    "weighted avg       0.82      0.84      0.81       212\n",
    "\n",
    "Confusion Matrix\n",
    "[[168   4]\n",
    " [ 30  10]]\n",
    "AUC: 0.6133720930232558\n",
    "\n",
    "\n",
    "\n",
    "004\n",
    "JUST ALPHA\n",
    "n=85\n",
    "Scores:\n",
    "0.8883495145631068\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.98      0.94       172\n",
    "           1       0.79      0.44      0.57        34\n",
    "\n",
    "    accuracy                           0.89       206\n",
    "   macro avg       0.84      0.71      0.75       206\n",
    "weighted avg       0.88      0.89      0.87       206\n",
    "\n",
    "Confusion Matrix\n",
    "[[168   4]\n",
    " [ 19  15]]\n",
    " \n",
    "004 ALPHA, AVE=3\n",
    "n=85, \n",
    " 0.8786407766990292\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.97      0.93       172\n",
    "           1       0.74      0.41      0.53        34\n",
    "\n",
    "    accuracy                           0.88       206\n",
    "   macro avg       0.81      0.69      0.73       206\n",
    "weighted avg       0.87      0.88      0.86       206\n",
    "\n",
    "Confusion Matrix\n",
    "[[167   5]\n",
    " [ 20  14]]\n",
    "AUC: 0.6913474692202461\n",
    "\n",
    "004 ALPHA Ave = 5\n",
    "0.8689320388349514\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.98      0.93       172\n",
    "           1       0.73      0.32      0.45        34\n",
    "\n",
    "    accuracy                           0.87       206\n",
    "   macro avg       0.81      0.65      0.69       206\n",
    "weighted avg       0.86      0.87      0.85       206\n",
    "\n",
    "Confusion Matrix\n",
    "[[168   4]\n",
    " [ 23  11]]\n",
    " \n",
    " \n",
    " \n",
    " -------------------------------------------------\n",
    " -----007-----\n",
    " n=70 norm\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8445945945945946\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.79      0.88       108\n",
    "           1       0.63      1.00      0.78        40\n",
    "\n",
    "    accuracy                           0.84       148\n",
    "   macro avg       0.82      0.89      0.83       148\n",
    "weighted avg       0.90      0.84      0.85       148\n",
    "\n",
    "Confusion Matrix\n",
    "[[85 23]\n",
    " [ 0 40]]\n",
    "AUC: 0.8935185185185185\n",
    "\n",
    "n=75 norm\n",
    "Scores:\n",
    "0.852112676056338\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.79      0.89       102\n",
    "           1       0.66      1.00      0.79        40\n",
    "\n",
    "    accuracy                           0.85       142\n",
    "   macro avg       0.83      0.90      0.84       142\n",
    "weighted avg       0.90      0.85      0.86       142\n",
    "\n",
    "Confusion Matrix\n",
    "[[81 21]\n",
    " [ 0 40]]\n",
    "AUC: 0.8970588235294118\n",
    "\n",
    "\n",
    "AVERAGING n=3:\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8716216216216216\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.82      0.90       108\n",
    "           1       0.68      1.00      0.81        40\n",
    "\n",
    "    accuracy                           0.87       148\n",
    "   macro avg       0.84      0.91      0.86       148\n",
    "weighted avg       0.91      0.87      0.88       148\n",
    "\n",
    "Confusion Matrix\n",
    "[[89 19]\n",
    " [ 0 40]]\n",
    "AUC: 0.912037037037037\n",
    "\n",
    "AVE=3 n=75\n",
    "Scores:\n",
    "0.8873239436619719\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.84      0.91       102\n",
    "           1       0.71      1.00      0.83        40\n",
    "\n",
    "    accuracy                           0.89       142\n",
    "   macro avg       0.86      0.92      0.87       142\n",
    "weighted avg       0.92      0.89      0.89       142\n",
    "\n",
    "Confusion Matrix\n",
    "[[86 16]\n",
    " [ 0 40]]\n",
    "AUC: 0.9215686274509804\n",
    "\n",
    "007 - AVE=5\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8740740740740741\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.82      0.90        95\n",
    "           1       0.70      1.00      0.82        40\n",
    "\n",
    "    accuracy                           0.87       135\n",
    "   macro avg       0.85      0.91      0.86       135\n",
    "weighted avg       0.91      0.87      0.88       135\n",
    "\n",
    "Confusion Matrix\n",
    "[[78 17]\n",
    " [ 0 40]]\n",
    "\n",
    "007 JUST BETA:\n",
    "n=80\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8518518518518519\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.83      0.89        95\n",
    "           1       0.69      0.90      0.78        40\n",
    "\n",
    "    accuracy                           0.85       135\n",
    "   macro avg       0.82      0.87      0.84       135\n",
    "weighted avg       0.87      0.85      0.86       135\n",
    "\n",
    "Confusion Matrix\n",
    "[[79 16]\n",
    " [ 4 36]]\n",
    "AUC: 0.8657894736842106\n",
    "\n",
    "007 JUST BETA:\n",
    "AVERAGING n=3:\n",
    "n=80:\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8962962962962963\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      0.86      0.92        95\n",
    "           1       0.75      0.97      0.85        40\n",
    "\n",
    "    accuracy                           0.90       135\n",
    "   macro avg       0.87      0.92      0.88       135\n",
    "weighted avg       0.92      0.90      0.90       135\n",
    "\n",
    "Confusion Matrix\n",
    "[[82 13]\n",
    " [ 1 39]]\n",
    "AUC: 0.9190789473684211\n",
    "\n",
    "007 JUST BETA AVE=3 n=75\n",
    "Scores:\n",
    "0.8943661971830986\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.87      0.92       102\n",
    "           1       0.75      0.95      0.84        40\n",
    "\n",
    "    accuracy                           0.89       142\n",
    "   macro avg       0.86      0.91      0.88       142\n",
    "weighted avg       0.91      0.89      0.90       142\n",
    "\n",
    "Confusion Matrix\n",
    "[[89 13]\n",
    " [ 2 38]]\n",
    "AUC: 0.9112745098039216\n",
    "\n",
    "\n",
    "007 JUST BETA Ave=5 n=75\n",
    "Scores:\n",
    "0.8591549295774648\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.84      0.90       102\n",
    "           1       0.69      0.90      0.78        40\n",
    "\n",
    "    accuracy                           0.86       142\n",
    "   macro avg       0.82      0.87      0.84       142\n",
    "weighted avg       0.88      0.86      0.86       142\n",
    "\n",
    "Confusion Matrix\n",
    "[[86 16]\n",
    " [ 4 36]]\n",
    "AUC: 0.8715686274509803\n",
    "\n",
    "007 JUST BETA Ave=5 n=80\n",
    "Scores:\n",
    "0.8814814814814815\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.87      0.91        95\n",
    "           1       0.75      0.90      0.82        40\n",
    "\n",
    "    accuracy                           0.88       135\n",
    "   macro avg       0.85      0.89      0.87       135\n",
    "weighted avg       0.89      0.88      0.88       135\n",
    "\n",
    "Confusion Matrix\n",
    "[[83 12]\n",
    " [ 4 36]]\n",
    "AUC: 0.8868421052631579\n",
    "\n",
    "\n",
    "007 JUST ALPHA\n",
    "Norm n=80\n",
    "Scores:\n",
    "0.8518518518518519\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.83      0.89        95\n",
    "           1       0.69      0.90      0.78        40\n",
    "\n",
    "    accuracy                           0.85       135\n",
    "   macro avg       0.82      0.87      0.84       135\n",
    "weighted avg       0.87      0.85      0.86       135\n",
    "\n",
    "Confusion Matrix\n",
    "[[79 16]\n",
    " [ 4 36]]\n",
    "AUC: 0.8657894736842106\n",
    "\n",
    "007 JUST ALPHA Ave=3 n=80\n",
    "0.8962962962962963\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      0.86      0.92        95\n",
    "           1       0.75      0.97      0.85        40\n",
    "\n",
    "    accuracy                           0.90       135\n",
    "   macro avg       0.87      0.92      0.88       135\n",
    "weighted avg       0.92      0.90      0.90       135\n",
    "\n",
    "Confusion Matrix\n",
    "[[82 13]\n",
    " [ 1 39]]\n",
    "AUC: 0.9190789473684211\n",
    "\n",
    "007 JUST ALPHA Ave=5 n=80\n",
    "0.8814814814814815\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.87      0.91        95\n",
    "           1       0.75      0.90      0.82        40\n",
    "\n",
    "    accuracy                           0.88       135\n",
    "   macro avg       0.85      0.89      0.87       135\n",
    "weighted avg       0.89      0.88      0.88       135\n",
    "\n",
    "Confusion Matrix\n",
    "[[83 12]\n",
    " [ 4 36]]\n",
    "AUC: 0.8868421052631579\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "-------002-------\n",
    "JUST BETA\n",
    "n=80\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1\n",
    " 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8344370860927153\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.91      0.89       223\n",
    "           1       0.70      0.63      0.67        79\n",
    "\n",
    "    accuracy                           0.83       302\n",
    "   macro avg       0.79      0.77      0.78       302\n",
    "weighted avg       0.83      0.83      0.83       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[202  21]\n",
    " [ 29  50]]\n",
    "AUC: 0.7693704944088097\n",
    "\n",
    "002\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.804635761589404\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.91      0.87       223\n",
    "           1       0.67      0.51      0.58        79\n",
    "\n",
    "    accuracy                           0.80       302\n",
    "   macro avg       0.75      0.71      0.72       302\n",
    "weighted avg       0.79      0.80      0.80       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[203  20]\n",
    " [ 39  40]]\n",
    "AUC: 0.708321507634671\n",
    "\n",
    "002\n",
    "Averaging = 3\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.7649006622516556\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.91      0.85       223\n",
    "           1       0.58      0.35      0.44        79\n",
    "\n",
    "    accuracy                           0.76       302\n",
    "   macro avg       0.69      0.63      0.65       302\n",
    "weighted avg       0.74      0.76      0.74       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[203  20]\n",
    " [ 51  28]]\n",
    "AUC: 0.6323721405460635\n",
    "\n",
    "002 - JUST BETA - AVE =3\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1\n",
    " 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8344370860927153\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.91      0.89       223\n",
    "           1       0.70      0.63      0.67        79\n",
    "\n",
    "    accuracy                           0.83       302\n",
    "   macro avg       0.79      0.77      0.78       302\n",
    "weighted avg       0.83      0.83      0.83       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[202  21]\n",
    " [ 29  50]]\n",
    "AUC: 0.7693704944088097\n",
    "\n",
    "Scores:\n",
    "0.7748344370860927\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.81      0.84       223\n",
    "           1       0.56      0.68      0.61        79\n",
    "\n",
    "    accuracy                           0.77       302\n",
    "   macro avg       0.72      0.75      0.73       302\n",
    "weighted avg       0.79      0.77      0.78       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[180  43]\n",
    " [ 25  54]]\n",
    "AUC: 0.7453595958449226\n",
    "\n",
    "\n",
    "002 - AVE = 5\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.804635761589404\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.91      0.87       223\n",
    "           1       0.67      0.51      0.58        79\n",
    "\n",
    "    accuracy                           0.80       302\n",
    "   macro avg       0.75      0.71      0.72       302\n",
    "weighted avg       0.79      0.80      0.80       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[203  20]\n",
    " [ 39  40]]\n",
    "AUC: 0.708321507634671\n",
    "\n",
    "002 - JUST BETA - n=5\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "[0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1\n",
    " 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0]\n",
    "Scores:\n",
    "0.8344370860927153\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.91      0.89       223\n",
    "           1       0.70      0.63      0.67        79\n",
    "\n",
    "    accuracy                           0.83       302\n",
    "   macro avg       0.79      0.77      0.78       302\n",
    "weighted avg       0.83      0.83      0.83       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[202  21]\n",
    " [ 29  50]]\n",
    "AUC: 0.7693704944088097\n",
    "\n",
    "\n",
    "\n",
    "002 JUST ALPHA\n",
    "Norm n=80\n",
    "0.8344370860927153\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.87      0.91      0.89       223\n",
    "           1       0.70      0.63      0.67        79\n",
    "\n",
    "    accuracy                           0.83       302\n",
    "   macro avg       0.79      0.77      0.78       302\n",
    "weighted avg       0.83      0.83      0.83       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[202  21]\n",
    " [ 29  50]]\n",
    "AUC: 0.7693704944088097\n",
    "\n",
    "002 JUST ALPHA Ave=3 N=80\n",
    "0.7873754152823921\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.80      0.85       222\n",
    "           1       0.57      0.76      0.65        79\n",
    "\n",
    "    accuracy                           0.79       301\n",
    "   macro avg       0.74      0.78      0.75       301\n",
    "weighted avg       0.82      0.79      0.80       301\n",
    "\n",
    "Confusion Matrix\n",
    "[[177  45]\n",
    " [ 19  60]]\n",
    "AUC: 0.7783954840916867\n",
    "\n",
    "002 JUST ALPHA Ave=5 N=80\n",
    "0.7748344370860927\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.87      0.85       223\n",
    "           1       0.58      0.52      0.55        79\n",
    "\n",
    "    accuracy                           0.77       302\n",
    "   macro avg       0.71      0.69      0.70       302\n",
    "weighted avg       0.77      0.77      0.77       302\n",
    "\n",
    "Confusion Matrix\n",
    "[[193  30]\n",
    " [ 38  41]]\n",
    "AUC: 0.6922290968950446\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results - norm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       747\n",
      "           1       0.60      0.58      0.59       189\n",
      "\n",
      "    accuracy                           0.84       936\n",
      "   macro avg       0.75      0.74      0.74       936\n",
      "weighted avg       0.83      0.84      0.84       936\n",
      "\n",
      "Confusion Matrix\n",
      "[[673  74]\n",
      " [ 79 110]]\n"
     ]
    }
   ],
   "source": [
    "#COMBINED CLASSIFICSATION REPORTS FOR EACH CLASSIFIER-TYPE\n",
    "\n",
    "def combine_strlists(lsts):\n",
    "    punc = '''!()-[]{};: '\"\\,<>./?@#$%^&*_~'''\n",
    "    combined_preds = []\n",
    "    for i in lsts:\n",
    "        for j in i:\n",
    "            if j not in punc:\n",
    "                new_point = int(j)\n",
    "                combined_preds.append(new_point)\n",
    "    return combined_preds\n",
    "\n",
    "y_test_norm = []\n",
    "y_pred_norm = []\n",
    "\n",
    "y_test_norm.append('[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "y_test_norm.append('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "y_test_norm.append('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "y_test_norm.append('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "\n",
    "y_pred_norm.append('[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0]')\n",
    "y_pred_norm.append('[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "y_pred_norm.append('[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "y_pred_norm.append('[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "\n",
    "y_test = combine_strlists(y_test_norm)\n",
    "y_pred = combine_strlists(y_pred_norm)\n",
    "\n",
    "print('Total results - norm')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix')\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(con_matrix)\n",
    "\n",
    "\n",
    "\n",
    "#---AVE=3----\n",
    "y_test_ave3 = []\n",
    "y_pred_ave3 = []\n",
    "\n",
    "y_test_ave3.append('[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]')\n",
    "y_test_ave3.append(\n",
    "\n",
    "y_pred_ave3.append('[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "'''row = [0, 1, 2, 3, 4, 5]\n",
    "new_row = []\n",
    "new_row.append(row[0])\n",
    "new_row.append(row[1])\n",
    "for j in range(2,len(row)-2,2):\n",
    "    print(j)\n",
    "    next_ave_1 = (row[j]+row[j-2]+row[j+2])/3.0\n",
    "    next_ave_2 = (row[j+1]+row[j-1]+row[j+3])/3.0\n",
    "    new_row.append(next_ave_1)\n",
    "    new_row.append(next_ave_2)\n",
    "new_row\n",
    "\n",
    "num_split = 5\n",
    "kfold = KFold(n_splits=num_split, shuffle=False)# random_state=seed)\n",
    "cvscores = []\n",
    "tot_cvscores = []\n",
    "\n",
    "y_all_labels = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "for train, test in kfold.split(np.zeros(y_all_labels.size)):\n",
    "    #print(train)\n",
    "    #print(test)\n",
    "    print(y_all_labels[test])\n",
    "        #model.fit(x_all[train],y_all_labels[train])'''\n",
    "\n",
    "a = [1,2,3,4,5]\n",
    "b = []\n",
    "con = np.concatenate((a, b))\n",
    "\n",
    "empty_array = np.array([1,2])\n",
    "to_append = np.array([1, 2, 3])\n",
    "\n",
    "combined_array = np.append(empty_array, to_append)\n",
    "print(combined_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
